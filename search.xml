<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[第三讲 事务隔离：为什么你改了我还看不见]]></title>
    <url>%2F2019%2F02%2F18%2F2019-02-18-2%2F</url>
    <content type="text"><![CDATA[提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。最经典的例子就是转账，你要给朋友小王转100块钱，而此时你的银行卡只有100块钱。 转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这100块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到“事务”这个概念了。 事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。MySQL是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如MySQL原生的MyISAM引擎不支持事务，这也是MyISAM被InnoDB取代的重要原因之一。 以InnoDB为例，剖析 MySQL 在事务支持方面的特定实现，并基于原理给出相应的实践建议。 隔离性和隔离级别事务涉及到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），这里来说说其中 I ，也就是“隔离性”。 当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。 首先明确一点，隔离级越高，效率越低。因此，需要在二者之间寻找一个平衡。SQL标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。逐一解释： 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 新数据存在内存里，InnoDB buffer poo 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 各级别效果假设数据表T中只有一列，其中一行的值为1，下面是按照时间顺序执行两个事务的行为。 12mysql&gt; create table T(c int) engine=InnoDB;insert into T(c) values(1); 事务A 事务B 启动事务查询得到值 1 启动事务 查询得到值 1 将 1 改成 2 查询得到值 V1 提交事务B 查询得到值 V2 提交事务 A 查询得到值 V3 在不同的隔离级别下，事务A会有哪些不同的返回结果，V1、V2、V3的返回值分别是什么。 若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。 若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。 若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。 读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。读已提交：别人改数据的事务已经提交，我在我的事务中才能读到。可重复读：别人改数据的事务已经提交，我在我的事务中也不去读。串行：我的事务尚未提交，别人就别想改数据。这4种隔离级别，并行性能依次降低，安全性依次提高。 重复读和读提交的性能差异 建立视图没什么成本的，就是拷贝一个事务数组；所以性能的差异不是体现在这里；一般我们说可重复的效率相对的低（其实也还好，不会低多少），主要还是因为可重复读的锁范围可能更大（有gap lock），锁时间更长（事务结束才释放），影响并发度 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。在“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；在“串行化”隔离级别下直接用加锁的方式来避免并行访问。 我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle数据库的默认隔离级别其实就是“读提交”，因此对于一些从Oracle迁移到MySQL的应用，为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”。 配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED 。可以用 show variables 来查看当前的值。 1234567891011mysql&gt; show variables like &apos;transaction_isolation&apos;;+-----------------------+----------------+| Variable_name | Value |+-----------------------+----------------+| transaction_isolation | READ-COMMITTED |+-----------------------+----------------+ 可重复读级别的应用总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，根据自己的业务情况来定。如需要“可重复读”的场景。 一个数据校对逻辑的案例。 假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。 这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。 事务隔离的实现再来看看事务隔离具体是怎么实现的。这里展开说明“可重复读”。 在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 假设一个值从 1 被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。 同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。 你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。 什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。 基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 在MySQL 5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有20GB，而回滚段有200GB的库。最终只好为了清理回滚段，重建整个库。 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。 事务的启动方式如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL的事务启动方式有以下几种： 显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。 set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。 有些客户端连接框架会默认连接成功后先执行一个set autocommit=0的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。 因此，我会建议你总是使用set autocommit=1, 通过显式语句的方式来启动事务。 但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用commit work and chain语法。 在autocommit为1的情况下，用begin显式启动的事务，如果执行commit则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行begin语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。 你可以在information_schema库的innodb_trx这个表中查询长事务，比如下面这个语句，用于查找持续时间超过60s的事务。 1select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 小结介绍了MySQL的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二讲 一条 sql 更新语句的执行]]></title>
    <url>%2F2019%2F02%2F18%2F2019-02-18-1%2F</url>
    <content type="text"><![CDATA[通过对一句 updata 语句，来解析 Mysql 的日志系统。 例如我们创建了表 T, 如下命令： 1mysql&gt; create table T(ID int primary key, c int); 更新语句： 1mysql&gt; update T set c=c+1 where ID=2; 更新语句也会同查询语句一样，通过连接器、分析器、优化器、执行器；最后到达存储引擎。 流程执行语句前要先连接数据库，这是连接器的工作。 在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也是一般不建议使用查询缓存的原因。 接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。 与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）。如果接触 MySQL ，那这两个词肯定是绕不过的。redo log 和 binlog 在设计上有很多有意思的地方，这些设计思路也可以用到自己的程序里 redo log举个例子：酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。如果有人要赊账或者还账的话，掌柜一般有两种做法： 一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉； 另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。 在生意红火柜台很忙时，掌柜会选择后者，因为前者操作实在是太麻烦了。得找到这个人的赊账总额那条记录，找到之后再拿出算盘计算，最后再将结果写回到账本上。 相比之下，还是先在粉板上记一下方便。如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？ MySQL 中 WAL 技术同样，在MySQL里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。 而粉板和账本配合的整个过程，其实就是MySQL里经常说到的 WAL 技术，WAL的全称是 Write-Ahead Logging ，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。 具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。 如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。 与此类似，InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么这块“粉板”总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。 write pos 是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint ，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 有了 redo log ，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe 。 要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。 binlog前面我们讲过，MySQL整体来看，其实就有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）。 Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。 为什么会有两份日志呢？因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是 MyISAM ，但是MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。 这两种日志有以下三点不同。 redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。 执行器先找引擎取 ID=2 这一行。 ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上1，比如原来是 N ，现在就是 N+1 ，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog ，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。 这里我给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。 你可能注意到了，最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤： prepare 和 commit ，这就是”两阶段提交”。 两阶段提交为了让两份日志之间的逻辑一致。 1 prepare阶段 -&gt; 2 写binlog -&gt; 3 commit当在2之前崩溃时重启恢复：后发现没有commit，回滚。备份恢复：没有binlog 。一致当在3之前崩溃重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog. 一致 怎样让数据库恢复到半个月内任意一秒的状态？binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的DBA承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog ，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。 当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做： 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库； 然后，从备份的时间点开始，将备份的binlog依次取出来，重放到中午误删表之前的那个时刻。 这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。 为什么日志需要“两阶段提交”。这里用反证法来进行解释。 由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。 仍然用前面的update语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0 ，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？ 先写 redo log 后写 binlog 。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。 先写 binlog 后写 redo log 。如果在 binlog 写完之后 crash ，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是0。但是 binlog 里面已经记录了 “把c从0改成1” 这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是1，与原库的值不同。 可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？ 其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用binlog来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。 简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。 小结通过更新语句，介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog 。 redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数建议设置成1，这样可以保证MySQL异常重启之后数据不丢失。 sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数建议设置成1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。 MySQL日志系统密切相关的“两阶段提交”。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。 问题文章的最后，留下的问题是一天一备跟一周一备的对比。 好处是“最长恢复时间”更短。 在一天一备的模式里，最坏情况下需要应用一天的binlog。比如，你每天0点做一次全量备份，而要恢复出一个到昨天晚上23点的备份。 一周一备最坏情况就要应用一周的binlog了。 系统的对应指标就是提到的RTO（恢复目标时间）。 当然这个是有成本的，因为更频繁全量备份需要消耗更多存储空间，所以这个RTO是成本换来的，就需要你根据业务重要性来评估了。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一讲 一条 sql 查询语句的执行]]></title>
    <url>%2F2019%2F02%2F18%2F2019-02-18%2F</url>
    <content type="text"><![CDATA[通过对一句 select 语句，来解析 Mysql 的基础架构。 1mysql&gt; select * from T where ID=10; 语句拆解语句在 MySQL 的各个功能模块中的执行过程： 大体来说，MySQL可以分为Server层和存储引擎层两部分。 Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。 在 create table 建表的时，未指定引擎类型，默认使用 InnoDB 。在 create table语句中使用 engine=memory, 来指定使用内存引擎创建表。从图中不难看出，不同的存储引擎共用一个 Server 层。 模块功能解析连接器连接器负责跟客户端建立连接、获取权限、维持和管理连接。 连接器示例：1.输入命令mysql -h$ip -P$port -u$user -p2.交互对话里面输入密码。直接在步骤1 -p 参数后输入命令，可能会密码泄露。所以一般在命令后单独输入 步骤解释：命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的TCP握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。 如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。 一个用户成功建立连接后，即使用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。 连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，可以在show processlist命令中看到它。文本中这个图是show processlist的结果，其中的Command列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。 12345678910mysql&gt; show processlist;+----+------+-----------------+------+---------+------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------------+------+---------+------+----------+------------------+| 4 | root | localhost:62435 | test | Query | 0 | starting | show processlist || 10 | root | localhost:62436 | test | Sleep | 16 | | NULL |+----+------+-----------------+------+---------+------+----------+------------------+2 rows in set (0.00 sec) mysql&gt; 客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数wait_timeout控制的，默认值是8小时。 如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。如果要继续连接数据库，需要重连，然后再执行请求了。 长连短连数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。 建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。 但是全部使用长连接后，你可能会发现，有些时候MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。 怎么解决这个问题呢？你可以考虑以下两种方案。 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 查询缓存连接建立后，就开始执行 select 语句。执行逻辑开始进行第二步：查询缓存。 MySQL拿到一个查询请求后，会先去查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。 但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。 查询缓存失效频繁只要有对一个表的更新，这个表上所有的查询缓存都会被清空。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。 指定是否查询缓存MySQL 提供了“按需使用”的方式。可以将参数 query_cache_type 设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用SQL_CACHE显式指定，像下面这个语句一样： 1mysql&gt; select SQL_CACHE * from T where ID=10； 需要注意的是，MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。 分析器若是未命中查询缓存（或是 MySQL 8.0 后的版本），就要真正执行语句。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析。 分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。 MySQL从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名T”，把字符串“ID”识别成“列ID”。 做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。 如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句select少打了开头的字母“s”。 123mysql&gt; elect * from t where ID=1;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;elect * from t where ID=1&apos; at line 1 一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。 ###优化器经过了分析器，MySQL就知道这条 sql 语句是要做什么了。但在开始执行之前，还要先经过优化器的处理。 优化器是在表里存在多个索引时，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的join： 1mysql&gt; select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20; 既可以先从表t1里面取出c=10的记录的ID值，再根据ID值关联到表t2，再判断t2里面d的值是否等于20。 也可以先从表t2里面取出d=20的记录的ID值，再根据ID值关联到t1，再判断t1里面c的值是否等于10。 两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。 优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。优化器是怎么选择索引的，有没有可能选择错等等，会在后面的文章中展开说明优化器的内容。 执行器MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，第三步就进入了执行器阶段，开始执行语句。 开始执行的时，会判断用户对这个表 T 是否有执行查询的权限。如果没有，就会返回权限错误，如下所示(在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。 123mysql&gt; select * from T where ID=10;ERROR 1142 (42000): SELECT command denied to user &apos;b&apos;@&apos;localhost&apos; for table &apos;T&apos; 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。 比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的： 调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 至此，这个语句就执行完成了。对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。 你会在数据库的慢查询日志中看到一个rows_examined的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。 在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。 小结介绍了MySQL的逻辑架构，对一个 SQL 语句完整执行流程的各个阶段，有一个初步的印象。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 服务器数据库创建]]></title>
    <url>%2F2018%2F12%2F20%2F2018-12-20%2F</url>
    <content type="text"><![CDATA[查看服务器数据库show databases; 创建库CREATE DATABASE database_name; 使用库use database_name; 查看数据库内的表show tables; 创建表 12345create table table_name(key1 int(12),key2 char(12)); 表名重命名alter table name1 rename as name2;字段重命名alter table table_name change t_name t_name_new varchar(20); 插入表记录 123insert into table_name(key1,key2,key3) values(01,&apos;name1&apos;,value1);insert into table_name values(02,&apos;name2&apos;,value2);insert into table_name(key1,key2) values(03,&apos;name3&apos;);]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 接口初解]]></title>
    <url>%2F2018%2F12%2F17%2F2018-12-17%2F</url>
    <content type="text"><![CDATA[接口接口：纯抽象类 * 所有成员函数都是抽象函数 * 所有成员变量都是 public static final * 方法都是共有的 12345[可见度] interface 接口名称 [extends 其他的接口名名] &#123; // 声明变量 // 抽象方法 [可见度] 返回类型 接口名称()；&#125; 类描述对象的属性和方法。接口则包含类要实现的方法。除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内所描述的所有方法，否则就必须声明为抽象类。另外，在 Java 中，接口类型可用来声明一个变量，他们可以成为一个空指针，或是被绑定在一个以此接口实现的对象。 1.接口可以多继承 一个接口能继承另一个接口，和类之间的继承方式比较相似。接口的继承使用extends关键字，子接口继承父接口的方法。 2.接口的方法声明必须是 public abstract 即便不写默认也是 3.接口里面不能包含方法的实现主体 4.类继承接口必须实现接口里申明的全部方法，除非该类是抽象类 5.类里面可以声明 public static final 修饰的变量 6.接口不能被实例化，但是可以被实现类创建 7.接口没有构造方法。 8.接口中所有的方法必须是抽象方法。 抽象函数/抽象类抽象类：表达概念而无法构造出实体对象的类抽象方法:表达概念而无法实现具体代码的函数 特点： 带有 abstract 修饰符的函数 有抽象函数的类一定是抽象类 抽象类不能制造对象 但是可以定义变量 任何集成了抽象类的非抽象类对象可以付给这个变量。 抽象类的子类必须付给父类中的所有抽象函数，否则子类也会变成抽象类。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>接口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 城堡游戏（代码优化思想）]]></title>
    <url>%2F2018%2F12%2F14%2F2018-12-14%2F</url>
    <content type="text"><![CDATA[城堡中有多个房间，用户通过输入north, south, east, west等来确认去哪一个房间（此时窗口会有提示转到哪个房间），如果此时多出一个房间，需要使用up, down才能到达，修改代码则需要代码具有可扩展性，对原来的代码进行优化来实现这个功能。 优化前代码结构： 优化路程将类中相同的代码抽离，转为一个公用的方法将注释的代码抽离成一个方法，供调用： 123456789101112131415private void nowRoom()&#123; System.out.println(&quot;现在你在&quot; + currentRoom); System.out.print(&quot;出口有：&quot;);// 将出口信息封装在Room类中，降低程序之间的耦合// if(currentRoom.northExit != null)// System.out.print(&quot;north &quot;) ;// if(currentRoom.eastExit != null)// System.out.print(&quot;east &quot;);// if(currentRoom.southExit != null)// System.out.print(&quot;south &quot;);// if(currentRoom.westExit != null)// System.out.print(&quot;west &quot;); System.out.println(currentRoom.getExitDesc()); System.out.println(); &#125; 将 Room 类中的变量转为私有变量Room 类和 Game 类有大量的代码出口相关，Game 类中大量使用了 Room 类中的成员变量；利用封装来降低类和类之间的耦合；便于代码后续的维护。 在将 Room 类的变量转为私有后，发现 Game 类中有几处报错；说明 Game 类中调用到了 Room 类的成员变量；第一处是上一步中提取的方法，阅读代码功能；是显示当前 Room 的出口信息。 优化思想：调用者不做被调用类的逻辑处理出口信息能否只在 Room 中做逻辑处理，Game 类中只负责调用就好。 做法：在 Room 类中增加 getExitDesc 方法。 1234567891011121314 public String getExitDesc()&#123;// 使用 StringBuffer 是因为 String 对象是管理者，每次对 String 对象的修改都是新增一个 String 对象，// 对系统开销比较大，但是 StringBuffer支持修改 StringBuffer sb = new StringBuffer(); if (northExit != null) sb.append(&quot;north &quot;); if (eastExit != null) sb.append(&quot;east &quot;); if (westExit != null) sb.append(&quot;west &quot;); if (southExit != null) sb.append(&quot;south &quot;); return sb.toString(); &#125; 这样在 Game类中的 nowRoom 方法中，只需要调用 getExitDesc 方法就能返回出口信息。 第二处错误是在 Game 类中， goRoom 方法中，显示的是玩家进入下一个房间后，显示出口信息。同样的，想办法让 Room 类中就处理其中的逻辑，直接返回给 Game 类下一个房间的出口信息。 在 Room 类中新增一个 getExit 方法，直接将 Game 类中的逻辑处理复制过来用。 12345678910111213141516public Room getExit(String direction)&#123; Room ret = null; if(direction.equals(&quot;north&quot;)) &#123; ret = northExit; &#125; if(direction.equals(&quot;east&quot;)) &#123; ret = eastExit; &#125; if(direction.equals(&quot;south&quot;)) &#123; ret = southExit; &#125; if(direction.equals(&quot;west&quot;)) &#123; ret = westExit; &#125; return ret;&#125; 减少代码中的硬编码优化思想：使用容器来代替硬编码Room 类有四个成员变量表示四个方向。使用 HashMap 容器来装载方向，这样方便以后新增方向变量，提高代码灵活性。 做法：去掉原有变量，新增一个 HashMap 容器变量。private HashMap&lt;String,Room&gt; exit = new HashMap&lt;String,Room&gt;();同步修改类方法中的 setExits 方法。因为使用了容器的原因，所以只能为 Room 对象一个个出口添加。 12345// 录入房间空间位置的方式改变，由原来的对一个房间的四个方向分别定义，改为对一个房间// 自定义方向以及该方向上的新房间public void setExit(String dir, Room room)&#123; exit.put(dir,room); &#125; 发现 Room类 中的 getExit 方法出现报错，可以通过容器直接返回房间的方向信息： 12345678910111213141516public Room getExit(String direction)&#123;// Room ret = null;// if(direction.equals(&quot;north&quot;)) &#123;// ret = northExit;// &#125;// if(direction.equals(&quot;east&quot;)) &#123;// ret = eastExit;// &#125;// if(direction.equals(&quot;south&quot;)) &#123;// ret = southExit;// &#125;// if(direction.equals(&quot;west&quot;)) &#123;// ret = westExit;// &#125; return exits.get(direction); &#125; getExitDesc 方法也要同步做修改，var.keyset() 方法获取 map 的 key 的集合。 123456789101112131415161718public String getExitDesc()&#123;// 使用 StringBuffer 是因为 String 对象是管理者，每次对 String 对象的修改都是新增一个 String 对象，// 对系统开销比较大，但是 StringBuffer支持修改 StringBuffer sb = new StringBuffer(); for (String dir : exits.keySet()) &#123; sb.append(dir+&quot; &quot;); &#125;// if (northExit != null)// sb.append(&quot;north &quot;);// if (eastExit != null)// sb.append(&quot;east &quot;);// if (westExit != null)// sb.append(&quot;west &quot;);// if (southExit != null)// sb.append(&quot;south &quot;); return sb.toString(); &#125; 因为修改了 Room 类中的房间出口信息设置方法，Game 类中的 creatRooms 方法报错。 1234567891011121314151617181920212223242526272829private void createRooms() &#123; Room outside, lobby, pub, study, bedroom; // 制造房间 outside = new Room(&quot;城堡外&quot;); lobby = new Room(&quot;大堂&quot;); pub = new Room(&quot;小酒吧&quot;); study = new Room(&quot;书房&quot;); bedroom = new Room(&quot;卧室&quot;); // 初始化房间的出口// outside.setExits(null, lobby, study, pub);// lobby.setExits(null, null, null, outside);// pub.setExits(null, outside, null, null);// study.setExits(outside, bedroom, null, null);// bedroom.setExits(null, null, null, study); outside.setExit(&quot;eastExit&quot;,lobby); outside.setExit(&quot;southExit&quot;,study); outside.setExit(&quot;westExit&quot;,pub); lobby.setExit(&quot;westExit&quot;,outside); pub.setExit(&quot;eastExit&quot;,outside); study.setExit(&quot;northExit&quot;,outside); study.setExit(&quot;eastExit&quot;,bedroom); bedroom.setExit(&quot;westExit&quot;,study); currentRoom = outside; // 从城堡门外开始 &#125; 到这里，如果想要增加一个新的出口信息，只要在 Game 类中初始化一个新的房间，增加新的出口信息类型就可以了； 以框架+数据来提高可扩展性优化思想：将硬编码改成 框架 + 数据城堡游戏中 main 函数中的 go,help,bye 三个命令解析，依旧是硬编码的；优化成框架和数据的形式。 优化做法： 命令的解析脱离 if-else 定义一个 Handle 来处理命令 用 Hash 表来保存命令和 Handler 之间的关系 字符串对应关系用 HashMap[为什么字符串对应一个东西通常都是用 HashMap？] 定义一个 HashMap，key 和 value 都必须是对象，城堡游戏中有的是，String 和调用一个函数。因此需要创建一个中间类 Handle，通过 handle 类的对象调用对应的函数。如下创建四个类。 12345678910111213141516171819202122232425262728293031323334353637383940//父类 Handlerpublic class Handler &#123; public void doCmd(String word)&#123; &#125; public boolean isBye() &#123; return false; &#125;&#125;// HandlerGopublic class HandlerGo extends Handler &#123; private Game game; public HandlerGo(Game game)&#123; this.game = game; &#125; @Override public void doCmd(String word) &#123; game.goRoom(word); &#125;&#125;// HandlerHelppublic class HandlerHelp extends Handler &#123; @Override public void doCmd(String word) &#123; System.out.println(&quot;迷路了吗？你可以做的命令有：go bye help&quot;); System.out.println(&quot;如：\tgo east&quot;); &#125;&#125;// handlerByepublic class HandlerBye extends Handler&#123; @Override public boolean isBye() &#123; return true; &#125;&#125; 在 Gmae 类初始化 Handle 类的 HashMap 对象，并在构造器中构建 不同功能的 Handle 对象放入 map 中； 1234567891011121314public class Game &#123; private Room currentRoom; /*用Hash表保存命令与Handler之间的关系*/ private HashMap&lt;String, Handler&gt; handlers = new HashMap&lt;String, Handler&gt;(); public Game() &#123; handlers.put(&quot;go&quot;, new HandlerGo(this)); handlers.put(&quot;bye&quot;, new HandlerBye()); handlers.put(&quot;help&quot;,new HandlerHelp()); createRooms(); &#125; ... 将原来 main 函数中的循环体，提取成一个新的方法： 12345678910111213141516171819202122232425262728293031public void play()&#123; Scanner in = new Scanner(System.in); while ( true ) &#123; String line = in.nextLine(); String[] words = line.split(&quot; &quot;);// 利用Hash表&lt;K, V&gt;的特性，如果用户输入&quot;bye&quot;，通过handler.get()得出handler// 类型下面这句就相当于：Handler handler = new HandlerBye(); Handler handler = handlers.get(words[0]); String value = &quot; &quot;; if (words.length &gt; 1)&#123; value = words[1]; &#125; if (handler != null)&#123;// 此时handler为HandlerBye型，没有value值 handler.doCmd(value);// HandlerBye继承了Handler中的isBye()方法并将其覆盖，此时handler.isBye()返回true if (handler.isBye())&#123; break; &#125; &#125;// if ( words[0].equals(&quot;help&quot;) ) &#123;// game.printHelp();// &#125; else if (words[0].equals(&quot;go&quot;) ) &#123;// game.goRoom(words[1]);// &#125; else if ( words[0].equals(&quot;bye&quot;) ) &#123;// break;// &#125; &#125; in.close(); &#125; 优化完成，代码运行正常；优化完成后，当需要新增动作命令时，只需要新增一个 handler类型，并在构造器里新增新类型的 map 键值对。而不用对 play 函数做改动。这就是通过 框架 + 数据 实现的可扩展性。 github代码地址 https://github.com/wengfe/JAVA/tree/master/castle简书地址：]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>代码优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 加密]]></title>
    <url>%2F2018%2F09%2F02%2F2018-09-02%2F</url>
    <content type="text"><![CDATA[关于Python加密1.简单的用base64模块这个是Python标准库里面的模块，用来做一个二进制的编码的模块！我们在网上明文传送的时候，可以用它来简单的伪装： 123import base64msg=b&apos;Hi,I am 007&apos;print (&apos;raw msg:&apos;,msg) 输出:raw msg: b’Hi,I am 007’ 12decode_msg=base64.b64encode(msg)print (&apos;decode msg:&apos;,decode_msg) 输出:decode msg: b’SGksSSBhbSAwMDc=’ (这就算加密的信息) 12msg=base64.b64decode(decode_msg)print (&apos;restore msg:&apos;,msg) 输出：restore msg: b’Hi,I am 007’ base64两个内置函数就可以实现非常简单的加密和解密，传输在网上的就变成一段乱七八糟的文字 2.深入加密，hashlib很多服务器上都有hashlib进行加密，好处就算这样的加密会用”加盐”的操作，就算加入一个混淆的字符串然后进行hash. 这里的salt就算加盐 1234567891011import hashlibpasswd=&apos;123456&apos;salt=&apos;aaa&apos;new_passwd=passwd+saltdecode_passwd=hashlib.md5(new_passwd.encode(&apos;utf-8&apos;)).hexdigest()print(decode_passwd)//**服务器上存储的一个KEY,不能泄漏**API_KEY=&apos;93a9e5bb1d598a453606e890f72bd393&apos;assert decode_passwd==API_KEYprint (&apos;ok&apos;) 这样的加密，其实很多交易所都是这样的加密方法 3.神级加密如果上面的几种加密还是不放心，Python里面可以用几十行代码搞定的神级加密！需要安装一个第三方库pycrypto,这个库非常牛，里面的加密方式非常多，我这里取最简单的一种AES（高标准加密)12345678910from Crypto.Cipher import AES//**密钥,长度必须为16**secret_key = &apos;a&apos;*16//**IV参数，长度必须为16，一个初始化的矢量**iv_param = &apos;b&apos;*16//**要加密的明文密码，长度必须是16的倍数，不足就补齐16位**passwd = &quot;1234567890123456&quot;print (&apos;Your passwd:&apos;,passwd) 输出:Your passwd: 1234567890123456 数据加密123aes = AES.new(secret_key, AES.MODE_CBC, iv_param)encrypt_data = aes.encrypt(passwd)print(&apos;encrypt data：&apos;, encrypt_data) 输出：encrypt data： b’\xa9Q\x9a\xcf\x1b\x86\x10z\x93\x00\x12\x02;\xef\xd6\x14’ 数据解密123aes= AES.new(secret_key, AES.MODE_CBC, iv_param)decrypt_data = aes.decrypt(encrypt_data)print(&apos;plain text：&apos;, decrypt_data) 输出：plain text： b’1234567890123456’ 这个加密非常安全，128个比特，而且有双重的密钥匙，你想破解非常麻烦，只有接收方知道这双重密钥才能破解！]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[appium 学习_1]]></title>
    <url>%2F2018%2F05%2F09%2F2018-05-09%2F</url>
    <content type="text"><![CDATA[虽然环境的安装比较麻烦，但我决定还是不要继续这个网上一搜就能搜到一大片文章的问题来浪费时间。第一篇主要就第一个例子-通过 appium 连接 android 安装一个 apk 来讲解。 Mac/Linux终端命令首先是放上一些 可能会用到的命令。事实上，我是几乎全用到了的。 adb 工具使用这个命令可以针对比较老的 appium，因为老版本的 appium 是需要在 capabilities 中指定 包名（appPackage）和启动页的（appActivity）这两个参数的。新版本的 appium（主要针对1.7.2及之后版本）会自动识别。只需要指定平台、设备名、app 路径三个参数就行。 12adb devices #获取连接主机的设备名aapt dump badging xxx.apk #获取测试包的信息 终端查看进程123ps aux | lesslsof -i tcp:8080 #查看8080 端口被什么进程占了kill -9 PIDNUM #关闭 PIDNUM 的进程 步骤编写动作脚本新建一个 AppiumPython 目录，在里面新建 case文件夹，在 case 文件夹下创建 start_appium.py 脚本文件。在 start_appium 中编写 capabilities 1234567891011#coding=utf-8from appium import webdrivercapabilities = &#123; &quot;platformName&quot;: &quot;Android&quot;, &quot;deviceName&quot;:&quot;127.0.0.1:21503&quot;,# 设备名随意 &quot;app&quot;:&quot;/Users/usr/Desktop/xxx.apk&quot; #app 路径&#125;webdriver.Remote(&quot;http://127.0.0.1:4723/wd/hub&quot;,capabilities) #IP地址和端口号需要与之后启动的 appium 中设定的地址和端口号一致 连接 android 设备连接实体机或者开启模拟器。通过 adb devices 来查看是否已经成功连接。 终端启动 appium直接在终端输入 appium 回车就可以了出现 Welcome to Appium v1.8.1 就表示成功启动了 1234MacBook-Pro:~% appium(node:20711) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.[Appium] Welcome to Appium v1.8.1[Appium] Appium REST http interface listener started on 0.0.0.0:4723 0.0.0.0 地址就是本地地址。 运行 脚本命令可以在 启动 appium 的终端窗口看到脚本运行情况。 遇到的问题在脚本中使用 get_window_size 方法。运行后就会跳异常： 1Message: The URL &apos;/wd/hub/session/799ef0f9-0735-41a3-bce9-ff017f27f3ff/window/size&apos; did not map to a valid resource 解决： 安装的appium-python-clicent 库里的 webdriver.py 没有get_window_size 这个方法。然后今天在 selenium 库下的 remote目录下的 webdriver.py 文件里发现了 get_window_rect 方法。我把代码里的 get_window_size 方法用 rect 方法替换，然后成功获取到了手机的屏幕大小； 过程：想群友拿了份老的 appium 库下的原因：]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>移动自动化测试</tag>
        <tag>appium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3 print篇]]></title>
    <url>%2F2018%2F04%2F16%2F2018-04-16%2F</url>
    <content type="text"><![CDATA[print函数原型1print(*objects, sep=&apos; &apos;, end=&apos;\n&apos;, file=sys.stdout, flush=False) 默认情况下，分隔符为空格sep=’ ‘，行结尾符为换行符end=’\n’，输出到标准输出file=sys.stdout，而且为带缓冲的flush=False。 print函数自定义分隔符或行尾结束符多数时候，不想要每次打印时行尾的换行符，设置end=’’即可，例如： 123456789101112&gt;&gt;&gt; for i in range(5):... print(i)... 01234&gt;&gt;&gt; for i in range(5):... print(i, end=&apos;&apos;)... &gt;&gt;&gt;01234 如果不知道print函数的sep关键字参数，很可能会写出如下丑陋的代码：123print(a + &apos;:&apos; + b + &apos;:&apos; + c) # Uglyprint(&apos;:&apos;.join([a, b, c])) # Still uglyprint(a, b, c, sep=&apos;:&apos;) # Better print函数打印输出到文件设置file关键字参数为带有write(string)方法的对象即可，例如： 12with open(&apos;somefile.txt&apos;, &apos;wt&apos;) as f: print(&apos;hello world!&apos;, file=f) 确保文件是以文本模式wt打开的，如果文件是二进制模式打开的话，打印就会失败 设置flush=True即可不带缓冲的打印输出文本。1print(&apos;some text&apos;, flush=True) 转载地址: 『Python3 print函数的四个关键字参数』：http://www.revotu.com/python3-print-function-keyword-arguments.html]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>print</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫代理篇]]></title>
    <url>%2F2018%2F03%2F02%2F2018-03-02%2F</url>
    <content type="text"><![CDATA[一、为何要设置User Agent 有一些网站不喜欢被爬虫程序访问，所以会检测连接对象，如果是爬虫程序，也就是非人点击访问，它就会不让你继续访问，所以为了要让程序可以正常运行，需要隐藏自己的爬虫程序的身份。此时，我们就可以通过设置User Agent的来达到隐藏身份的目的，User Agent的中文名为用户代理，简称UA。 User Agent存放于Headers中，服务器就是通过查看Headers中的User Agent来判断是谁在访问。在Python中，如果不设置User Agent，程序将使用默认的参数，那么这个User Agent就会有Python的字样，如果服务器检查User Agent，那么没有设置User Agent的Python程序将无法正常访问网站。 Python允许我们修改这个User Agent来模拟浏览器访问，它的强大毋庸置疑。 二、常见的User Agent 1.AndroidMozilla/5.0 (Linux; Android 4.1.1; Nexus 7 Build/JRO03D) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.166 Safari/535.19Mozilla/5.0 (Linux; U; Android 4.0.4; en-gb; GT-I9300 Build/IMM76D) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30Mozilla/5.0 (Linux; U; Android 2.2; en-gb; GT-P1000 Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1 2.FirefoxMozilla/5.0 (Windows NT 6.2; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0Mozilla/5.0 (Android; Mobile; rv:14.0) Gecko/14.0 Firefox/14.0 3.Google ChromeMozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.94 Safari/537.36Mozilla/5.0 (Linux; Android 4.0.4; Galaxy Nexus Build/IMM76B) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.133 Mobile Safari/535.19 4.iOSMozilla/5.0 (iPad; CPU OS 5_0 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A334 Safari/7534.48.3Mozilla/5.0 (iPod; U; CPU like Mac OS X; en) AppleWebKit/420.1 (KHTML, like Gecko) Version/3.0 Mobile/3A101a Safari/419.3 上面列举了Andriod、Firefox、Google Chrome、iOS的一些User Agent，直接copy就能用。]]></content>
      <categories>
        <category>python 爬虫</category>
      </categories>
      <tags>
        <tag>User Agent</tag>
        <tag>IP 代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 项目4 文章评论功能]]></title>
    <url>%2F2018%2F02%2F28%2F2018-02-28-1%2F</url>
    <content type="text"><![CDATA[主要是为熟悉，使用 Post 方法增加文章详情页评论功能。 本文django 表单创建流程： 准备工作 创建渲染表单 数据校验 数据存储 定制化表单 评论页面准备工作：django 自带表单系统处理步骤： 渲染表单 绑定表单 返回校验结果 此处新建了一个文章详情页来创建表单功能，表单内容为评论部分；因此此处新添加了数据模型，重新分配了 url。 在 model 添加评论模型123456class comment(models.Model): name = models.CharField(null=True, blank=True, max_length=50) comment = models.TextField() def __str__(self): return self.comment 然后再终端中进行数据合并，执行命令： 12345678910% python3 manage.py makemigrationsMigrations for &apos;django_demo&apos;: django_demo/migrations/0006_auto_20180228_0754.py - Create model comment - Alter field tag on article% python3 manage.py migrateOperations to perform: Apply all migrations: admin, auth, contenttypes, django_demo, sessionsRunning migrations: Applying django_demo.0006_auto_20180228_0754... OK view 添加逻辑12345def detail(request): context = &#123;&#125; comment_list = Comment.objects.all() context[&apos;comment_list&apos;] = comment_list return render(request, &apos;detail.html&apos;, context) url 分配url在 url 中 引入view内的 detail 1from django_demo.views import first_try, index, detail 在 urlpatterns 中添加 url 1path(r&apos;detail/&apos;, detail, name=&apos;detail&apos;), 渲染表单创建表单表单在 views.py 中创建。创建的方式与数据模型的创建非常相似。 引入 forms 创建表单函数 12345from django import formsclass CommentForm(forms.Form): name = forms.CharField(max_length=50) comment = forms.CharField() 实例化 表单，并带入数据模型当中。在 detail 数据模型类中 定义表单对象，并添加到内容中。 1234567def detail(request): form = CommentForm context = &#123;&#125; comment_list = Comment.objects.all() context[&apos;comment_list&apos;] = comment_list context[&apos;form&apos;] = form return render(request, &apos;detail.html&apos;, context) 模板层渲染 绑定表单 &amp; 返回校验结果在 views.py 中的 detail 数据模型下 修改代码如下： 12345678910111213def detail(request): if request.method == &apos;GET&apos;: form = CommentForm if request.method == &apos;POST&apos;: #绑定表单， 是进行数据校验的前置步骤 form = CommentForm(request.POST) print(form) print(form.errors) context = &#123;&#125; comment_list = Comment.objects.all() context[&apos;comment_list&apos;] = comment_list context[&apos;form&apos;] = form return render(request, &apos;detail.html&apos;, context) 一般在绑定表单后，就会触发数据验证，若有错误会将错误信息填写入 errorlist 中，可以通过print(form.errors) 来打印出。 表单数据存储需要 导入redirect， 1from django.shortcuts import render, redirect 然后在 detail 数据模型中添加代码 1234567891011121314151617181920def detail(request): if request.method == &apos;GET&apos;: form = CommentForm if request.method == &apos;POST&apos;: # 绑定表单， 是进行数据校验的前置步骤 form = CommentForm(request.POST) # 判断绑定的表单是否通过数据验证 if form.is_valid(): # 表单数据通过后，会将数据存储在 cleaned_data 中 name = form.cleaned_data[&apos;name&apos;] comment = form.cleaned_data[&apos;comment&apos;] c = Comment(name=name, comment=comment) c.save() # redirect 重定向回 name=detail 的 url return redirect(to=&apos;detail&apos;) context = &#123;&#125; comment_list = Comment.objects.all() context[&apos;comment_list&apos;] = comment_list context[&apos;form&apos;] = form return render(request, &apos;detail.html&apos;, context) 当 校验信息返回 false 时，会直接将错误信息装填在绑定表单时生成的错误列表中，然后装填在form 中，进行错误信息的渲染。所以不需要进行 else 的逻辑判断。 ps. form.is_valid() 以及 form = CommentForm(request.POST) 都会触发数据验证 这一步完成后，就能在 detail 页面进行评论了。 定制化表单 添加更加详细的验证 修改前段的表现形式 定制化表单的验证逻辑首先我们需要把 views.py 文件中的 CommentForm 类解耦到 form.py 文件中。 新建 form.py 文件 123456from django import formsclass CommentForm(forms.Form): comment = forms.CharField() name = forms.CharField(max_length=50) 接下来在该文件中，添加表单的逻辑。 自带的数据校验：12345678class CommentForm(forms.Form): name = forms.CharField(max_length=50) comment = forms.CharField( widget=forms.Textarea(), error_messages=&#123; &apos;required&apos;: &apos;input your comment, please&apos; &#125; ) 在需要添加校验的字段后添加参数 error_message， 复写错误提示语；一般提示语有三类required，invalid，max_length以字典形式写入。 这个自带的数据校验器，我并没有生效。 数据验证器在 form.py 中引入 from django.core.exceptions import ValidationError 然后定义数据验证逻辑，在 error_messages 中写入 validators 列表中 123456789101112131415161718192021def words_validator(comment): if len(comment) &lt; 4: raise ValidationError(&apos;Not enough words&apos;)def comment_validator(comment): if &apos;a&apos; in comment: raise ValidationError(&apos;&quot;a&quot; is must not&apos;)class CommentForm(forms.Form): name = forms.CharField(max_length=50) comment = forms.CharField( widget=forms.Textarea(), error_messages=&#123; &apos;required&apos;: &apos;input your comment, please&apos;, &apos;invalid&apos;: &apos;invalid&apos;, &apos;max_length&apos;: &apos;too much&apos; &#125;, validators=[words_validator, comment_validator] ) 验证器不仅能在表单的数据校验中使用，也可以在数据模型中使用。 定制表单的手工渲染对报错信息进行单独的手工渲染。 现在的报错样式： 手工渲染表单删除原先的 form.as_p 123456789101112&lt;form class=&quot;ui tiny form&quot; method=&quot;post&quot;&gt; &#123;% for field in form %&#125; &lt;div class=&quot;field&quot;&gt; &#123;&#123; field.label &#125;&#125; &#123;&#123; field &#125;&#125; &lt;/div&gt; &#123;% endfor %&#125; &#123;% csrf_token %&#125; &lt;button type=&quot;submit&quot; class=&quot;ui blue button&quot; &gt;Click&lt;/button&gt; &lt;/form&gt; 返回网页端，进行测试，发现评论内容无法进行数据验证。 渲染报错信息 1234567891011121314151617181920212223242526272829 &#123;# semantic error form 布局#&#125; &lt;form class=&quot;ui error tiny form&quot; method=&quot;post&quot;&gt;&#123;# 判断是否存在 error 信息#&#125; &#123;% if form.errors %&#125; &lt;div class=&quot;ui error message&quot;&gt; &#123;&#123; form.errors &#125;&#125; &lt;/div&gt; &#123;% for field in form %&#125;&#123;# 遍历表单字段，不通过数据校验的字段渲染成出错样式 并给出提示#&#125; &lt;div class=&quot;&#123;&#123; field.errors|yesno:&apos;error,&apos; &#125;&#125; field&quot;&gt; &#123;&#123; field.label &#125;&#125; &#123;&#123; field &#125;&#125; &lt;/div&gt; &#123;% endfor %&#125; &#123;% else %&#125; &#123;% for field in form %&#125; &lt;div class=&quot;field&quot;&gt; &#123;&#123; field.label &#125;&#125; &#123;&#123; field &#125;&#125; &lt;/div&gt; &#123;% endfor %&#125; &#123;% endif %&#125; &#123;% csrf_token %&#125; &lt;button type=&quot;submit&quot; class=&quot;ui blue button&quot;&gt;Click&lt;/button&gt; &lt;/form&gt; 源码地址: 『NiuCodeLesson/DjangoWeb/DjangoWebFirst/』:https://github.com/wengfe/NiuCodeLesson/tree/master/DjangoWeb/DjangoWebFirst]]></content>
      <categories>
        <category>python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 项目3 文章分类功能]]></title>
    <url>%2F2018%2F02%2F28%2F2018-02-28%2F</url>
    <content type="text"><![CDATA[主要是为熟悉，使用 get 方法获取分类文章。 在 model 层增加 tag 字段。 在 view 层编写逻辑，根据请求返回结果。 template 与用户交互 Time Will Tell Time: T template 网页展示给用户 M model 是数据 Will： V view 视图层 U url 链接视图的urlTell: T template 喜欢，处理视图 model 层添加 Tag 字段12345678910class Article(models.Model): headline = models.CharField(null=True, blank=True, max_length=500) content = models.TextField(null=True, blank=True) TAG_CHOICES = &#123; (&apos;teach&apos;, &apos;Teach&apos;), (&apos;life&apos;, &apos;Life&apos;) &#125; # choices 参数： 提供一组下拉菜单选项 tag = models.TextField(null=True, blank=True, max_length=5, choices=TAG_CHOICES) 重新定义数据库中 Article 类在终端中执行命令 python3 manage.py makemigrations python3 manage.py migrate这两条命令，下面示意图是因为我已经合并过了。 正确的提示跟 web 框架下的 Django 框架下，新建，合并数据库的提示类似。在定义好新的 article tag 字段后，需要在 网页代码中修改为文章的标签 123&lt;div class=&quot;ui mini tag label&quot;&gt; &#123;&#123; article.tag &#125;&#125;&lt;/div&gt; views 中的逻辑12345678910111213print(request) print(&apos;===&apos; * 30) print(dir(request)) print(&apos;===&apos; * 30) print(type(request)) queruseet = request.GET.get(&apos;tag&apos;) print(queruseet) if queruseet: article_list = Article.objects.filter(tag=queruseet) else: # 数据库操作方法，从指定表中取得所有值 table_mame.objects.all() article_list = Article.objects.all() 在 views.py 文件 index 函数下的上次代码基础上添加上述 if/else 代码，做逻辑处理。若是请求中存在标签，就将存有该表的文章添加到文章列表，予以展示，否则展示全部文章。 Template 中的交互在 html 中 categories 标签分类下设置 href 链接 这样点击 categories 中的标签，就能在 url 后添加参数。]]></content>
      <categories>
        <category>python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 项目2 创建笔记]]></title>
    <url>%2F2018%2F02%2F27%2F2018-02-27%2F</url>
    <content type="text"><![CDATA[创建模板从 Django 项目1 文章的结尾处开始。首先需要贮备好静态网页。将静态网页的 html 文件放入项目目录下的 template 文件夹下，网页的其他静态文件放入项目下新建的 static 文件夹下。 ps.部分代码因为与 hexo 语法冲突，无法渲染，采用图片形式。 使用静态文件标签更新 html 内的静态资源路径。在 html 标签的上一行 添加 staticfiles 123&#123;% staticfiles %&#125;&lt;html&gt;... 静态文件标签会加载所有的静态文件。模板语言分三部分： 模板标签 123 &#123;% %&#125; ``` 2. 模板变量 12345678910111213143. 模板过滤器 &lt;img src=&quot;https://lh3.googleusercontent.com/-dlMKuY1RJss/WpZVMW75ngI/AAAAAAAAAJY/RzW0L694B-g0ZneUIkSo4Bkf6A7EKyd8QCHMYCw/I/15198016478635.png&quot; width = &quot;400&quot; alt=&quot;template_filter&quot;/&gt;## 创建后台Django 自带一个可视化后台，方便用户管理数据。### 登录后台启动我们的项目，在端口号后填入 `/admin`可以看到，一个后台登录页面。因为没有超级管理员所以登录不了。#### 创建超级管理员在终端中输入 `python3 manage.py createsuperuser` 创建超级管理员。 Username (leave blank to use ‘fuyiweng’): adminEmail address:Password:Password (again):Superuser created successfully.123456789101112email 可以不填。密码输入不可见。回到后台页面，使用刚刚创建的超级管理员登录。![](https://lh3.googleusercontent.com/-6JESCuvzIss/WoKYRqt4rVI/AAAAAAAAAHg/c87qxEawttsZZqhGVzTO7lhk1oXv4rPhQCHMYCw/I/15185080999231.png)可以看到有两张表，但是没有上一篇文章中的 People 表。### 关联自定义表回到 IDE ，admin.py 就是我们后台管理数据库的文件，需要向这个文件中注册我们创建的表。在文件中添加： from django_demo.models import People admin.site.register(People)1234刷新网页，出现 People 表，通过网页在表中添加一个对象，存储后显示为一个 People object 。但并不方便我们通过这个管理后台。返回 models 文件的 People 类下，增加 `__str__` 函数，返回对象 name def __str__(self): return self.name 1234567891011121314刷新网页，People 表下的对象显示为对象名。#### 新增 Article 表重新温习一下，添加表流程1. 在 models 文件下新增 Aritcle 类2. 在 admin 文件下 引入 Aritcle 类， 并 regist3. 在终端执行 `python3 manage.py makemigrations `4. 在终端执行 `python3 manage.py migrate`## model 引入数据在 views 中新建一个函数，作为主页。正确的引用数据的方法是创建一个实例，将所有数据装载在变量中。 def index(request): context = {} # 数据库操作方法，从指定表中取得所有值 table_mame.objects.all() article_list = Aritcle.objects.all() # 往字典中填入数据 context[&apos;article_list&apos;] = article_list index_page = render(request, &apos;first_web_2.html&apos;, context) return index_page 123## 模板语言遍历模板 ``` 在模板中调整路径]]></content>
      <categories>
        <category>python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 中的 render 函数]]></title>
    <url>%2F2018%2F02%2F13%2F2018-02-13%2F</url>
    <content type="text"><![CDATA[render 函数渲染函数，接收三个参数 render(request, x.html, context)x.html ： 模板名称context： 上下文 之前我一直认为，上下文是比较难以理解的概念，最近找到一个比较容易理解的方法。 There’s a block waiting in the sky.加粗字体换成 Taxi Pie 可以形成不同的句意。 Django 中的上下文就相当于是数据库中取得的数据与网页显示部分的映射]]></content>
      <categories>
        <category>python</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>note</tag>
        <tag>render</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 中的 web 常见框架(Django 项目1)]]></title>
    <url>%2F2018%2F02%2F11%2F2018-02-11%2F</url>
    <content type="text"><![CDATA[大包大揽 Django 力求精简 web.py 和 Tornabo 新生代微框架 Flask 和 Bottle 微框架优势： 聚焦业务逻辑 学习成本低 灵活性和伸缩性较强 劣势： 很多逻辑需要手动编写 安装大量模块后体积较大 Flask保持核心简单，易扩展。不包括数据库抽象层，表单验证等。 可通过添加扩展的方式添加功能 安装1pip install flask 通过导入 flask 模块，来验证安装是否成功。 表单开发表单标签用于声明表单范围，位于表单标签中的元素将被提交语法： `属性： method， Enctype， action 表单域表单域包含文本框，密码框等多种类型语法： &lt;input.../&gt;属性： type，name，value 表单域种类文本框： &lt;…type:text&gt;密码框：&lt;…type:password&gt;文本区域：&lt;…type:textarea&gt;文件上传框：&lt;…type:file&gt;单选框：&lt;…type:radio&gt;复选框：&lt;…type:checkbox&gt; 复选框的值为数组形式。 表单按钮提交按钮复位按钮一般按钮 表单提交方式GETPOST 数据放置在 HTML Header 中提交。 GET 可以被浏览器缓存 数据暴露 URL适合：单纯请求数据，不进行其他操作 表单数据较短，不超过 1024 字符 对安全性要求一般 POST URL 可以被缓存，数据不被缓存 请求不便分享，没有长度限制适合：不仅仅用于请求，需要将数据插入数据库内 表单数据过长 传送的数据不是 ASCII 编码 Djongo优势： 详细的文档 全套结局啊方案 强大的 URL 路由配置 完善的自主管理后台 劣势： 紧耦合 自带 ORM 不够强大 Template 较弱 MTV 模型工作模型： 创建虚拟环境 virtualenv如果你生产或开发环境需同时支持 Python 2 和 Python 3 ，那就需要 virtualenv。我们是从零开始学习 Django，所以可以直接使用 venv。简单来说，venv 模块是 Python 3.3 版本之后，标准库自带的虚拟环境创建和管理工具，在 Python 3 版本是代替 virtualenv。 使用 venv 在当前系统中创建出一个环境，该环境可以跟当前系统互不影响，你可以随意折腾。出现问题，只要删除即可，不会影响到当前系统。另外，有了 virtualenv 虚拟环境之后，我们就可以把那个文件夹整体拷贝了，部署起来方便很多。 步骤：一. 创建项目目录创建项目主目录。并进入主目录，创建项目目录 123mkdir DjangoWebcd DjangoWebmkdir DjangoWebFirst 二. 创建虚拟环境，激活虚拟环境--no-site-packages 表示不安装系统中的第三库创建虚拟环境。 1virtualenv --no-site-packages env_python 三. 使用 pycharm 创建项目 在 location 填入项目目录所在路径在 Interpreter 填入新建的虚拟环境在 Application 填入第一个网站的名字 创建好后，目录类似这样： 创建数据库 12345678910111213141516171819202122python3 manage.py migrateOperations to perform: Apply all migrations: admin, auth, contenttypes, sessionsRunning migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying sessions.0001_initial... OK(env_python) fuyiweng@fuyiwengdeMacBook-Pro:~/Documents/study/NiuCodeLesson/DjangoWeb/DjangoWebFirst% python3 manage.py makemigrationsMigrations for &apos;django_demo&apos;: django_demo/migrations/0001_initial.py - Create model People 新建数据库： 在 models.py 中新建一个 People 类， 在终端执行：python3 manage.py makemigrations 创建建表策略 执行表合并： 123456789NiuCodeLesson/DjangoWeb/DjangoWebFirst% python3 manage.py migrateOperations to perform: Apply all migrations: admin, auth, contenttypes, django_demo, sessionsRunning migrations: Applying django_demo.0001_initial... OK``` 在 views 中创建页面：在 views 文件中，新建 first_try 类： from django.shortcuts import renderfrom django.http import HttpRequest, HttpResponsefrom django_demo.models import Peoplefrom django.template import Context, Template Create your views here.def first_try(request): person = People(name=’jack’, job=’officer’) html_string = ‘’’ diango Hello, ‘’’ # 将 html 字符转成模板 t = Template(html_string) # 组上下文 c = Context({&apos;person&apos;: person}) # 渲染模板 web_page = t.render(c) return HttpResponse(web_page) ``` 在 urls 中增加 first_try 的 url： 引入 first_try from django_demo.views import first_try 增加路径 urlpatterns 下添加 path(r&#39;first_try/&#39;, first_try), 完成。]]></content>
      <categories>
        <category>python</category>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL 查询优化]]></title>
    <url>%2F2018%2F02%2F08%2F2018-02-08%2F</url>
    <content type="text"><![CDATA[本文主要目的就是对数据库的优化查询，但查询过程中碰到了一个不明缘由的问题，希望有大神能够帮忙解释一波。 目的从 csv 文件中随机选取 100 条 Ip 地址，并在表中查询这 100条 ip 的所在地。 步骤 读取样本，组装列表 表建立索引 优化 sql 语法 联合查询 读取文件读取文件和上一篇文章所讲的一样，利用 with 语法避免文件句柄关闭操作，给 open 函数增加 encoding 参数。 然后将读取的数据进行拆分和整理： 123456789with open(&apos;./ipdata.csv&apos;, &apos;r&apos;, encoding=&apos;utf-8&apos;) as f: lines = f.readlines()nl_p_list = []for l in lines: ls = l.strip().split(&apos;,&apos;, 4) c1, c2, c3, c4, c5 = ls[0], ip2int(ls[1]), ip2int(ls[2]), ls[3], ls[4] nl = [c1, c2, c3, c4, c5] nl_p_list.append(nl) 表建立索引使用 navicat 连接表，进入 「设计表」 模块，为 startip 和 endip 建立索引。 优化 sql 语法如果使用复杂语法的 sql 语句，是无法利用索引大幅提升查询效率的，比如通过 between and 查询： SELECT * FROM ipdata WHERE IpNum BETWEEN startip AND endip 因为 ip 是连续的，所以只要这个 Ip 地址大于或等于某一个号段的起始地址，那么依照降序排序第一的 ip 段的所在地，就是被查询的 ip 地址的所在地。 SELECT * FROM ipdata WHERE IpNum &gt;= startip ORDER BY startip DESC LIMIT 1 经过对比发现，查询速度果然是有质的飞跃。但也出现了问题。问题详情我会在文末写明。 联合查询利用索引的 sql 语句果然是如有神助，在我的运行环境里， between and 查询语句，查询 100 条记录需要 32s+ ，但在优化后能提升到 0.7s 左右。 但是在使用联合查询后，还能提升将近 2 倍的速率。 联合查询的 sql 语法： 123SELECT t1.* FROM (SELECT * FROM ipdata WHERE 1780997668 &gt;= startip ORDER BY startip DESC LIMIT 1) t1UNION ALLSELECT t2.* FROM (SELECT * FROM ipdata WHERE 3425736747 &gt;= startip ORDER BY startip DESC LIMIT 1) t2; 下一步，就是加工 sql 联合语句了。联合查询的 sql 语句，不宜过长，比较适合的长度就是 100 条。 1234sql_str = &apos;SELECT &#123;0&#125;.* FROM (SELECT * FROM ipdata WHERE %s &gt;= startip ORDER BY startip DESC LIMIT 1) &#123;0&#125;&apos;for i in range(len(ip_list)): sql_list.append(sql_str.format(&apos;t&apos; + str(i)) % ip_list[i])sql = &apos; union all &apos;.join(sql_list) 使用 format 函数填充别名， %s 填充 IP 地址 。最后执行 sql 语句： 1cursor.execute(sql) 效果也是有的，将查询的速度提升到了 0.3s 左右。 至此， sql 的数据表查询优化部分那就结束了。 遇到的灵异现象如图所示，我注释了 t1, t2, t3, t4 之间的代码。 时间段 含义 运行速度 t0 ~ t1 联合优化 sql 语句查询 0.0318 t1 ~ t2 优化 sql 语句查询 9.5367 t3 ~ t2 between and 语句查询 1.1920 t4 ~ t3 联合 between and 语句查询 0.0 事实上，除了 t0 ~ t1 之间的时间是大致在 0.03s ~ 0.07s 波动，剩余的三个时间段的代码已经被我注释，理论上应该是不耗费时间的，但会随机在剩余的三个时间段 打印出 9s 左右的耗时。希望有大神能够帮助一波。 源码地址: 『NiuCodeLesson/insertSQL/』：https://github.com/wengfe/NiuCodeLesson/tree/master/insertSQL]]></content>
      <categories>
        <category>python</category>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL 批量插入操作]]></title>
    <url>%2F2018%2F02%2F07%2F2018-02-07%2F</url>
    <content type="text"><![CDATA[对数据库的增删改查平时的工作中用的比较多，也比较熟悉。忽然发现都没有使用过 insert 操作，因此在学习 python 的过程中，通过 mysql.connector 对 44w行 的 ip地址记录进行数据库批量插入工作。 步骤分为以下五步： 1. 数据格式整理 2. 创建表 3. 连接表 4. 读取本地文件数据 5. 批量写入 数据格式整理首先查看所拿到的数据，并整理：分别在终端中使用 head ipdata.csv 和 tail ipdata.csv 来查看文件的头部和尾部数据，对其规律进行分析。 12345678910111213141516171819202122:~/Documents/study/NiuCodeLesson/insertSQL% head ipdata.csv1,0.0.0.0,0.255.255.255,IANA,保留地址2,1.0.0.0,1.0.0.255,澳大利亚,CZ88.NET3,1.0.1.0,1.0.3.255,福建省,电信4,1.0.4.0,1.0.7.255,澳大利亚,CZ88.NET5,1.0.8.0,1.0.15.255,广东省,电信6,1.0.16.0,1.0.31.255,日本,Beacon服务器7,1.0.32.0,1.0.63.255,广东省,电信8,1.0.64.0,1.0.127.255,日本,広島県中区大手町Energia通信公司9,1.0.128.0,1.0.255.255,泰国,CZ88.NET10,1.1.0.0,1.1.0.255,福建省,电信:~/Documents/study/NiuCodeLesson/insertSQL% tail ipdata.csv444954,223.255.252.0,223.255.253.255,福建省,电信444955,223.255.254.0,223.255.254.255,新加坡,滨海湾金沙私人有限公司444956,223.255.255.0,223.255.255.255,澳大利亚,CZ88.NET444957,224.0.0.0,224.255.255.255,IANA,CZ88.NET444958,225.0.0.0,239.255.255.255,IANA保留地址,用于多点传送444959,240.0.0.0,247.255.255.255,IANA保留地址,CZ88.NET444960,248.0.0.0,248.255.255.255,IANA保留地址,CZ88.NET444961,249.0.0.0,254.255.255.255,IANA保留地址,CZ88.NET444962,255.0.0.0,255.255.254.255,CZ88.NET,444963,255.255.255.0,255.255.255.255,纯真网络,2014年10月25日IP数据 查看后我们可以大致将数据分为 5 列，「序号」，「起始IP」，「终止IP」，「所在地」，「运营商」。 创建表经过格式的分析，我们就可以创建一个表的结构了。注：事实上分析数据规律比建表要重要的多，因为本文重点不在此处，所以概过。 首先通过 navicat 创建本地的数据库。数据库格式如下图： 连接表首先连接本地数据库因为我的表示创建在本地数据库下的，连接的库的时候不需要添加 host 参数连接本地数据库的代码如下： 1conn = mysql.connector.connect(user=&apos;root&apos;, password=&apos;admin&apos;, database=&apos;test&apos;) 连接远程数据库的代码如下： 1conn = connection.MySQLConnection(host=host_d, user=user_d, password=password_d, database=database_d) 读取 csv 数据文件一般来说，读取文件的方法有两种；推荐以下方式来读取文件，可以避免忘记关闭文件句柄的尴尬： 12with open(&apos;./ipdata.csv&apos;, &apos;r&apos;) as f: lines = f.readlines() 读取文件格式采坑在读取文件的过程中发现了报错。 报错信息：1UnicodeDecodeError: &apos;ascii&apos; codec can&apos;t decode byte 0xe4 in position 29: ordinal not in range(128) 原因分析：出错的原因是因为 csv 内的编码方式与程序环境编码方式不一致所致。csv 的编码格式是 gbk， 只要能够用 unicode 编码格式处理读取进来的数据就解决了。 搜索解决方案：自从上次瞎捷豹连续操劳后，已经很久没有让它出门了，这次又要有劳它了。经过搜索后，发现很多方案： 方案一 代码头部申明编码有两种写法，然而在试验后，表示并没有解决问题ㄟ( ▔, ▔ )ㄏ。 1# -*- coding: utf-8 -*- 1# coding = utf-8 方案二 IDE 设置编码格式虽然在 「偏好设置 - Editor - File Encodings」 内全都设置（默认设置）了 UTF-8，但是在读入数据文件 ipdata.csv 的时候，还是出现了错误。我也很奇怪为什么没有生效。 方案三 修改默认 encoding 格式 在代码头部导入 sys 库； 重载 sys 库，网上说 Python 文件运行后，会删除 setdefaultencoding 方法？ 设置默认 encoding 格式。 123import sysreload(sys) sys.setdefaultencoding(&apos;utf-8&apos;) 运行后显示找不到 setdefaultending 方法. 瞎捷豹愤而暴走，告诉我因为在 py3 中默认的编码格式为 unicode 解码？所以取消了 setdefaultending 方法。 正解：引入 codecs 库codecs 库中的 open 方法可以添加 encoding 参数，完美解决。 1234import codecswith open(&apos;./ipdata.csv&apos;, &apos;r&apos;, encoding=&apos;utf-8&apos;) as f: lines = f.readlines() 后来发现其实 3.6 版本的 py 早就集成了 open 函数的 encoding 参数。所以并不用导入 codecs 库。 批量写入插入操作的 sql 写法为 : 1insert into tablename (key1, key2, key3...) values (value1, value2, value3...) 使用 cursor.executemany() 方法来执行批量插入操作 方法为： 12cursor = conn.cursor()ret = cursor.executemany(&apos;insert into ipdata (id, startip, endip, country, carrier) values (%s, %s, %s, %s, %s)&apos;, nl_p_list) 失去连接报错12055: Lost connection to MySQL server at &apos;127.0.0.1:3306&apos;, system error: 32 Broken pipe 猜测是数据量太大所致，所以对读入的文件进行切片，分批插入表中； 12345for i in range(int(len(nl_p_list)/1000 +1)): tmp_nl_p_list = nl_p_list[i*1000: (i+1)*1000] # 批量插入表中 ret = cursor.executemany(&apos;insert into ipdata (id, startip, endip, country, carrier) values (%s, %s, %s, %s, %s)&apos;, tmp_nl_p_list) 数据库插入中文错误出现了新的报错，查看报错信息： 11366 (HY000): Incorrect string value: &apos;\xE4\xBF\x9D\xE7\x95\x99...&apos; for column &apos;carrier&apos; at row 1 对报错信息显示 异常的 string 值，截取报错信息交给瞎捷豹，很快找到了解决方案；还是编码格式锅，不过这次是表结构编码格式不符。 在 navicat 表设计 - DDL 中查看 ipdata 的表结构： 12345678CREATE TABLE `ipdata` ( `id` int(11) NOT NULL, `startip` bigint(20) DEFAULT NULL, `endip` bigint(20) DEFAULT NULL, `country` text, `carrier` text, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=latin1; 发现表编码为 latin1 。 果然不是 utf-8。通过 navicat 查询功能修改表编码格式，输入代码并执行： 1alter table ipdata convert to character set utf8; 重新查看表结构： 12345678CREATE TABLE `ipdata` ( `id` int(11) NOT NULL, `startip` bigint(20) DEFAULT NULL, `endip` bigint(20) DEFAULT NULL, `country` text, `carrier` text, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 重新运行代码，数据成功写入表中。 使用 navicat 的查询功能： select count(*) from ipdata 得到记录行数 444963，写入记录正常。 计划通！ 参考链接： 『mysql.connector 批量插入』：https://my.oschina.net/hhdys412/blog/182762 源码地址: 『NiuCodeLesson/insertSQL/』：https://github.com/wengfe/NiuCodeLesson/tree/master/insertSQL]]></content>
      <categories>
        <category>python</category>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLAlchemy-ORM]]></title>
    <url>%2F2018%2F02%2F06%2F2018-02-06%2F</url>
    <content type="text"><![CDATA[上一篇所用的代码，是廖雪峰大大 python 数据库章节中的 SQLAlchemy 中的部分。因为踩到不少坑，所以又找到相关的资料进行学习。这一片主要将 sqlalchemy-orm 部分进行总结。ORM（Object Relational Mapper）可以理解为「将数据库中的表映射为程序中的类」。表中的一行即为该类的一个实例。 在使用 sqlalchemy 之前，需要先导入相关的库，在导入之前当然也是需要先安装。因为在代码中写入了大量的注释，所以就多 BB 了，文末会贴上本文代码的 github 的项目地址。在终端输入： 1pip install sqlalchemy 打开 pycharm 新建一个项目，然后导入以下库： 12345import sqlalchemyfrom sqlalchemy import create_engine, ForeignKeyfrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy import Column, String, Integerfrom sqlalchemy.orm import sessionmaker 注：第二行的最后一个库是之后双表建立外键的时候需要添加的库 创建「表-类」映射创建表123456789101112131415161718192021222324# 利用数据库字符串构造engine, echo为True将打印所有的sql语句engine = create_engine(&apos;sqlite:///foo.db&apos;, echo=True)# 首先需要生成一个BaseModel类,作为所有模型类的基类Base = declarative_base()class User(Base): __tablename__ = &apos;user&apos; id = Column(Integer, primary_key=True) name = Column(String) fullname = Column(String) passward = Column(String) def __repr__(self): return &apos;&lt;User(name=&quot;%s&quot;, fullname=&quot;%s&quot;, passward=&quot;%s&quot;)&gt;&apos; % ( self.name, self.fullname, self.passward)# 创建所有表,如果表已经存在,则不会创建# Base.metadata.create_all(engine)# 删除所有表# Base.metadata.drop_all(engine) 创建表实例创建一个 User 实例， sqlalchemy ORM 通过 session（会话）来操作表，一个 session 实例可以添加多个事务，然后通过 commit 提交事务，未提交的表操作事务是不会反馈到表中。 123456789101112131415161718192021222324#创建一个 User 类实例ed_user = User(name=&apos;ed&apos;, fullname=&apos;Ed jones&apos;, passward=&apos;edspassward&apos;)# print(ed_user)# 利用Session对象连接数据库#创建会话类和会话类的对象Session = sessionmaker(bind=engine)session = Session()# 向事务会话中添加实例对象，向表中插入数据需要提交事务， 调用 commit() 方法# session.add(ed_user)##查询符合条件的第一条# our_user = session.query(User).filter_by(name=&apos;ed&apos;).first()# 相等于下方的 sql 语句# select * from User where name=&apos;ed&apos; limit 1;## session.add_all([# User(name=&apos;wendy&apos;, fullname=&apos;Wendy Williams&apos;, passward=&apos;foobar&apos;),# User(name=&apos;wendy2&apos;, fullname=&apos;Wendy Williams&apos;, passward=&apos;foobar&apos;),# User(name=&apos;wendy3&apos;, fullname=&apos;Wendy Williams&apos;, passward=&apos;foobar&apos;)# ])# session.commit() 通过 session 事务进行查询操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#查询全部# print(session.query(User).all())#查询符合条件的第一条# our_user = session.query(User).filter_by(name=&apos;ed&apos;).first()#排序# for row in session.query(User).order_by(User.id):# print(row)# 查询 in 操作# for row in session.query(User).filter(User.name.in_([&apos;ed&apos;, &apos;wendy&apos;])):# print(row)# 查询 not in 操作# for row in session.query(User).filter(~User.name.in_([&apos;ed&apos;, &apos;wendy&apos;])):# print(row)# count 操作# print(session.query(User).filter(User.name ==&apos;ed&apos;).count())# and 和 or 操作, 需要导入模块# from sqlalchemy import and_, or_# for row in session.query(User).filter(and_(User.name == &apos;ed&apos;, User.fullname == &apos;Ed jones&apos;)):# print(row)# for row in session.query(User).filter(or_(User.name == &apos;ed&apos;, User.name ==&apos;wendy&apos;)):# print(row)# 创建外键from sqlalchemy import ForeignKeyfrom sqlalchemy.orm import relationship, backrefclass Address(Base): __tablename__ = &apos;addresses&apos; id = Column(Integer, primary_key=True) email_address = Column(String, nullable=False) user_id = Column(Integer, ForeignKey(&apos;user.id&apos;)) # 关联 User 表主键为外键，此处为 多对1 user_i = relationship(&quot;User&quot;, backref=backref(&apos;addresses&apos;, order_by=id)) def __repr__(self): return &quot;&lt;Address(email_address=&apos;%s&apos;)&gt;&quot; % self.email_address# Base.metadata.create_all(engine)# jack = User(name=&apos;jack&apos;, fullname=&apos;Jack Bean&apos;, passward=&apos;giffs&apos;)# jack.addresses = [# Address(email_address=&apos;jack@google.com&apos;),# Address(email_address=&apos;j25@yahoo.com&apos;)]## session.add(jack)# session.commit()# 双表联合查询for u, a in session.query(User, Address).\ filter(User.id == Address.user_id).\ filter(Address.email_address == &apos;jack@google.com&apos;).\ all(): print(u, a) 表数据修改操作123456789101112# 表修改# 造数据he_user = User(id=15, name=&apos;he&apos;, fullname=&apos;He jones&apos;, passward=&apos;edspassward&apos;)# session.add(he_user)# session.commit()# 使用merge方法，如果指定的主键已存在，修改记录，不存在新增一条记录session.merge(he_user)session.commit()# 关闭 sessionsession.close() github 地址：NiuCodeLesson/SQLalchemytest/SQLAlchemy.py]]></content>
      <categories>
        <category>python</category>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>SQLAlchemy</tag>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLAlchemy 预使用 -- 本地环境配置]]></title>
    <url>%2F2018%2F02%2F01%2F2018-02-01%2F</url>
    <content type="text"><![CDATA[因为之前使用 Python 操作数据库表时，目的是为了辅助工作，所以是直接对公司测试服务器上的数据库进行操作的。这次因为在学习 ORM ，所以需要在本地创建数据库。踩了一堆的烂坑，不得不说，大学时候没有听一节课，付出的时间代价会更大，我花了一天的时间进行踩坑学习才补回。 SQLAlchemy 是 python 平台上较为成熟的 ORM 框架。ORM -&gt; 对象关系映射，用于实现面向对象编程语言里不同类型系统的数据之间的转换。从效果上说，它其实是创建了一个可在编程语言里使用的–“虚拟对象数据库”抛开百度百科，就我的使用方向说，就是建立函数与数据库表之间的映射关系，所以需要映射的数据库表的是需要事先创建好的。我就是在这里踩了大坑。 安装本地 MySQL首先需要启动本地的 MySQLserver，我使用的是 Mac，前往官网下载，直接安装就好了。安装好后会给你一个随机密码。请记住这个密码。 当然忘记了问题也不大。 链接本地数据库这里问题就有点多了，当我安装好 MySQL 后，打开 Navicat 新建本地数据库链接的时候，跳出很多的小问题。 Can’t connect to remote MySQL server with error 61一只瞎捷豹乱搜，找到原因： Mac 下安装mysql，安装完成后是无用户无密码的状态，并且数据库只有 information_schema 也找到了解决之道: 为 root 账户新建密码。 鬼知道为什么无用户无密码状态，还给了我一个默认密码。按照随便找到的解决方法指导： [x] 关闭本地 MySQL 服务（在系统偏好设置的最下面一栏） [x] 进入 MySQL 文件目录下 [x] 启动超级账户 [x] 安全模式启动 MySQL [ ] 另起终端，使用 root 用户启动 MySQL:执行 mysql -u root [ ] 为root用户设置新的密码 UPDATE mysql.user SET Password=PASSWORD(&#39;password&#39;) WHERE User=&#39;root&#39;; [ ] 刷新，生效设置。FLUSH PRIVILEGES; 1234567/usr/local/mysql/binsudo suPassword:sh-3.2# ./mysqld_safe --skip-grant-tables &amp;[1] 33563sh-3.2# 2018-02-01T05:43:01.6NZ mysqld_safe Logging to &apos;/usr/local/mysql-5.7.21-macos10.13-x86_64/data/fuyiwengdeMacBook-Pro.local.err&apos;.2018-02-01T05:43:01.6NZ mysqld_safe Starting mysqld daemon with databases from /usr/local/mysql-5.7.21-macos10.13-x86_64/data 嗯，没错，我卡在了第五步 T&gt;T。 终端启用 MySQL 命令经过了惨无人道的瞎捷豹二次搜索，又成功找到了答案。 首先查看是否已添加 MySQL 的 PATH 路径 echo $PATH 如果能找到 mysql 的 PATH 路径（这是不可能的），问题解决 找不到，添加 MySQL 的路径，PATH=&quot;$PATH&quot;:/usr/local/mysql/bin 查看是否添加成功 12$ which mysql/usr/local/mysql/bin/mysql 如上所示，就是添加成功，我们可以继续放回上一个问题继续操作了。注：添加的 MySQL 路径为临时路径，关闭此终端后，下次打开将不再能运行 Your password has expired. To log in you must change it using a client that supports expired passwords.whatFuc—-A?瞎捷豹有点累，所以这次凭着我的三级英语，解密了这英文。密码过期，需要改密码。所以我刚刚改的是一个加密码？/usr/local/mysql/bin/mysqladmin -u root -p password输入旧密码，新密码。 然后就碰上了交学费的问题。 1049 (42000): Unknown database ‘test’ 和 1146 (42S02): Table ‘test.user’ doesn’t exist在之前配置了 MySQL 路径的终端中 使用 mysql 命令，show databases 果然发现没有需要链接的表。 12345678910mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec) 创建数据库和表吧，这里对自己的蠢不予置评。 Q^Q 我竟然还在这花了1个小时。 再次运行代码，皆大欢喜。 参考链接：终端数据库管理修改数据库密码]]></content>
      <categories>
        <category>python</category>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>SQLAlchemy</tag>
        <tag>MYSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 xlrd,xlwt 操作 excel]]></title>
    <url>%2F2018%2F01%2F23%2F2018-01-23%2F</url>
    <content type="text"><![CDATA[本来我是要写一个删除数据库日志的脚本来辅助工作(这个脚本故事放到以后再说)，因为考虑到数据库删除后没有数据备份，当时想着可以在删除操作之前把查询到的数据库记录挑选几个主键外键写到本地 excel 内, 所以简单学习了一下 python 对 excel 的操作。 值得注意的是， xlrd 和 xlwt 是分开的两个库，另外还有功能补充的 xlutils 库。安装时候需要分别执行： 123pip install xlrdpip install xlwtpip install xlutils 并且在使用的时候，如果要使用也要分别 import 导入。 以下是 xlrd/xlwt 的基础操作： xlrd 读取数据1234567891011121314151617181920212223242526272829&gt;&gt;&gt; import xlrd,xlwt,os&gt;&gt;&gt; wb = xlrd.open_workbook(&apos;/Users/fuyiweng/Downloads/源码/Python处理Excel入门/input.xls&apos;)#获得所有表格名&gt;&gt;&gt; print(wb.sheet_names())[&apos;data&apos;]#通过sheet名或序号得到表格&gt;&gt;&gt; sheet = wb.sheet_wb.sheet_by_index( wb.sheet_by_name( wb.sheet_loaded(wb.sheet_names(&gt;&gt;&gt; sheet = wb.sheet_by_name(&apos;data&apos;)#获得 data 表 行列数&gt;&gt;&gt; print(sheet.nrows)11&gt;&gt;&gt; print(sheet.ncols)3#打印第一行&gt;&gt;&gt; print(sheet.row(0))[text:&apos;时间&apos;, text:&apos;人数1&apos;, text:&apos;人数2&apos;]&gt;&gt;&gt; print(sheet.row(1))[xldate:42736.0, number:16.0, number:26.0]#获取单元格&gt;&gt;&gt; print(sheet.cell(1,2))number:26.0#ctype = 1 # 类型 0 empty,1 string, 2 number, 3 date, 4 boolean, 5 error&gt;&gt;&gt; print(sheet.cell(1,2).ctype)2&gt;&gt;&gt; print(sheet.cell(1,2).value)26.0 另外读取的时候注意，所读取的数据是否是以下xlrd 对 excel 内容分成的 7 种枚举类型 123456789(XL_CELL_EMPTY,XL_CELL_TEXT,XL_CELL_NUMBER,XL_CELL_DATE,XL_CELL_BOOLEAN,XL_CELL_ERROR,XL_CELL_BLANK, # for use in debugging, gathering stats, etc) = range(7) xlwt 写入数据打开 excel 文件123456789&gt;&gt;&gt; import xlrd,xlwt,os #通过xlrd 打开excel 文件&gt;&gt;&gt; wb = xlrd.open_workbook(&apos;/Users/fuyiweng/Downloads/源码/Python处理Excel入门/input.xls&apos;)&gt;&gt;&gt; type(wb)&lt;class &apos;xlrd.book.Book&apos;&gt; #通过xlwt.Workbook()转为可写模式&gt;&gt;&gt; wb = xlwt.Workbook()&gt;&gt;&gt; type(wb)&lt;class &apos;xlwt.Workbook.Workbook&apos;&gt; 写入数据1sheetname.write(row,col,value,style) 这里的 style 其实就是这个内容单元格的格式。 123456#写入第一行,标题栏style=xlwt.easyxf(&apos;align: vertical center, horizontal center&apos;)wsheet.write(0,0,u&apos;时间&apos;,style)wsheet.write(0,1,u&apos;人数1&apos;,style)wsheet.write(0,2,u&apos;人数2&apos;,style)wsheet.write(0,3,u&apos;总分&apos;,style)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>excel</tag>
        <tag>xlrd/xlwt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟训练营第二期]]></title>
    <url>%2F2018%2F01%2F19%2F2018-01-19-1%2F</url>
    <content type="text"><![CDATA[这是菜鸟训练营的第二期，主要是文件目录相关的问题，第三期的内容是数据分析相关的题目，我可能不会再继续去做了 原题：题目：mini文件搜索工具每个人电脑上都安装了Python无论是py2.7还是py3.6,假如你的是py2.7:搜索整个py2.7下面的所有目录(包括子目录)，里面的所有文件: 统计出整个py2.7目录下一共有多少个文件夹和文件 找到文件大小最大的哪个文件 找到文件名最长的哪个文件 解题：123456789101112131415161718192021222324252627282930313233343536373839404142434445from __future__ import divisionimport ospath=&apos;/Users/fuyiweng/Desktop/hero&apos;def search_file(path): folders = [] files_info = [] if not os.path.exists(path): print(&apos;Path : &#123;&#125; not exists!&apos;.format(path)) return None for root,dirs,files in os.walk(path): folders.extend(dirs) for f in files: #得到文件全路径，需要使用os.path.join(dirpath, name). f_path=os.path.join(root,f) #得到文件大小 f_size=round(os.path.getsize(f_path),3) files_info.append((f,f_size,f_path)) display(folders,files_info)def display(folders,files_info): print(&apos;folders: &apos;,folders) print(&apos;files_info &apos;,files_info) longest_file=sorted(files_info,key=lambda x:len(x[0]),reverse=True)[0][0] largest_file=sorted(files_info,key=lambda x:x[1],reverse=True)[0][2] largest_file_size=sorted(files_info,key=lambda x:(x[1]),reverse=True)[0][1] print(&apos;Total folders:&#123;&#125;,Total files:&#123;&#125;&apos;.\ format(len(folders),len(files_info))) print(&apos;Longest file name:&#123;&#125;,len:&#123;&#125;&apos;.\ format(longest_file,len(longest_file))) print(&apos;Largest file name:&#123;&#125; : size:&#123;&#125;&apos;.\ format(largest_file,str(round(largest_file_size/1024/1024))+&apos;M&apos;)) print(&apos;Total size:&#123;&#125;&apos;.format(sum([item[1] for item in files_info])))search_file(path) 解析：通过函数 os.walk() 函数来获取指定路径下的所存在的文件夹、文件、文件路径，将文件信息 append() 函数增加到列表中，然后通过 sorted() 排序，展示文件信息。 format格式化函数，基本语法是通过 {} 和 : 来代替以前的 % 。 不限个参数，位置可以不按顺序12345678&gt;&gt;&gt;&quot;&#123;&#125; &#123;&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;) # 不设置指定位置，按默认顺序&apos;hello world&apos; &gt;&gt;&gt; &quot;&#123;0&#125; &#123;1&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;) # 设置指定位置&apos;hello world&apos; &gt;&gt;&gt; &quot;&#123;1&#125; &#123;0&#125; &#123;1&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;) # 设置指定位置&apos;world hello world&apos; 设置参数123456789print(&quot;名：&#123;name&#125;, 地址 &#123;url&#125;&quot;.format(name=&quot;wengfe&quot;, url=&quot;https://wengfe.github.io/&quot;)) # 通过字典设置参数site = &#123;&quot;name&quot;: &quot;日暮&quot;, &quot;url&quot;: &quot;https://wengfe.github.io/&quot;&#125;print(&quot;网站名：&#123;name&#125;, 地址 &#123;url&#125;&quot;.format(**site)) # 通过列表索引设置参数my_list = [&apos;日暮&apos;, &apos;https://wengfe.github.io/&apos;]print(&quot;网站名：&#123;0[0]&#125;, 地址 &#123;0[1]&#125;&quot;.format(my_list)) # &quot;0&quot; 是必须的 数字格式化12&gt;&gt;&gt; print(&quot;&#123;:.2f&#125;&quot;.format(3.1415926));3.14 数字 格式 输出 描述 3.1415926 {:.2f} 3.14 保留小数点后两位 3.1415926 -3.1415926 {:+.2f} 3.14 -3.14 带符号保留小数点后两位 3.1415926 {:.0f} 3 不保留小数 5 {:0&gt;2d} 05 数字补零，填充左侧，宽度2 5 {:x&lt;4d} 5xxx 数字补x，填充右侧，宽度4 10000000 {:,} 10,000,000 以逗号分隔数字 0.25 {:.2%} 25.00% 百分比格式 1000000000 {:.2e} 1.00e+09 指数计数 13 {:10d} 13 右对齐，(默认)宽度10 13 {:&lt;10d} 13 左对齐，宽度10 13 {:^10d} 13 中间对齐，宽10 进制转换以十进制 11 为例：12345678910111213&apos;&#123;:b&#125;&apos;.format(11) &apos;&#123;:d&#125;&apos;.format(11)&apos;&#123;:o&#125;&apos;.format(11)&apos;&#123;:x&#125;&apos;.format(11)&apos;&#123;:#x&#125;&apos;.format(11)&apos;&#123;:#X&#125;&apos;.format(11) 10111113b0xb0XB 此外我们可以使用大括号 {} 来转义大括号，如下实例 1print (&quot;&#123;&#125; 对应的位置是 &#123;&#123;0&#125;&#125;&quot;.format(&quot;here&quot;)) os.walk因为 format 占据了很大的篇幅，所以就简单说一下 os.walk.os.walk() 方法用于通过在目录树种游走输出在目录中的文件名，向上或者向下。 walk()方法语法格式： 1os.walk(top[, topdown=True[, onerror=None[, followlinks=False]]]) top 是你所要便利的目录的地址 topdown 为真，则优先遍历top目录，否则优先遍历top的子目录(默认为开启) onerror 需要一个 callable 对象，当walk需要异常时，会调用 followlinks 如果为真，则会遍历目录下的快捷方式(linux 下是 symbolic link)实际所指的目录(默认关闭) os.walk 的返回值是一个生成器,需要不断遍历，来获得所有的内容。 每次遍历返回的对象都是三元组(root,dirs,files) root 所指的是当前正在遍历的这个文件夹的本身的地址dirs 是一个 list ，内容是该文件夹中所有的目录的名字(不包括子目录)files 同样是 list , 内容是该文件夹中所有的文件(不包括子目录)如果topdown 参数为真，walk 会遍历top文件夹，与top文件夹中每一个子目录。 简单实例： 12345import osfor root, dirs, files in os.walk(path): print(root) print(dirs) print(files) format 参考链接: http://www.runoob.com/python/att-string-format.html 菜鸟教程 os.walk 参考链接: http://www.runoob.com/python/os-walk.html 菜鸟教程 https://www.jianshu.com/p/bbad16822eab MikuLovely]]></content>
      <categories>
        <category>python</category>
        <category>exercise</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>菜鸟训练营</tag>
        <tag>format</tag>
        <tag>sorted</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟训练营第一期]]></title>
    <url>%2F2018%2F01%2F19%2F2018-01-19%2F</url>
    <content type="text"><![CDATA[我刚刚学习 Python 的时候就加入了一个小密圈，现在应该说是星球了。当时感觉水平次的很，当然现在也是只能谢谢寻常的逻辑代码。别说高级应用，甚至几个高级函数也不会用几个。不过自觉应该可以去做一下之前星球里的题目了。 因为自己写的代码比较无趣就贴上星主的代码。 第七题原题：有一串长的字符串 names=”LI XIA ,ZHAO MING ,LAO WANG *,DA XIONG &gt;,LI MEI MEI,CHANG JIANG,LI QIANG,ZHANG WU JI,ZHANG SAN FENG,DU GU QIU BAI,QIAO FENG” 要求： 过滤出所以的名字，去掉每个名字的左右的空格和乱码，每个名字的首字母大小比如’LAO WANG *’，处理成’Lao Wang’ 统计出所有名字里面名字最长 统计出同姓的人的名单 解题：12345678910names = &apos;LI XIA ,ZHAO MING ,LAO WANG *,DA XIONG &gt;,LI MEI MEI,&apos;\ &apos;CHANG JIANG,LI QIANG,ZHANG WU JI,ZHANG SAN FENG,&apos;\ &apos;DU GU QIU BAI,QIAO FENG&apos;def problem7(names): names_dict = &#123;name.title().strip(&apos; &gt;*&apos;):len(name) for name in names.split(&apos;,&apos;)&#125; print(sorted(names_dict.items(),key=lambda x:x[1],reverse=True))problem7(names) 解析两句代码解题，sorted 排序key 指定为名字长度，逆序排序增加属性 reverse=True 另外增加sorted 和 sort 的区别 函数 用法 效果 sorted sorted(a) 返回排序后的对象，不改变原对象顺序 sort a.sort() 改变原对象的排列顺序 第八题原题:数字1到5可以被写成:one,two,three,four,five,因此这些字母的总长度为:3+3+5+4+4=19,现在求序列1到1000(包括1000),这些数字写成单词，总长度为多少？ 注意: 比如 342(three hundred and forty-two)为23字母,空格和-不计算 比如 115(one hundred and fifteen)为20个字母 比如 1000(one hundred)为11个字母 解题:12345678910111213141516171819202122232425262728293031323334353637383940414243444546mapping=&#123;1:&apos;one&apos;,2:&apos;two&apos;,3:&apos;three&apos;,4:&apos;four&apos;,5:&apos;five&apos;, 6:&apos;six&apos;,7:&apos;seven&apos;,8:&apos;eight&apos;,9:&apos;nine&apos;,10:&apos;ten&apos;, 11:&apos;eleven&apos;,12:&apos;twelve&apos;,13:&apos;thirteen&apos;,14:&apos;fourteen&apos;,15:&apos;fifteen&apos;, 16:&apos;sixteen&apos;,17:&apos;seventeen&apos;,18:&apos;eighteen&apos;,19:&apos;nineteen&apos;,20:&apos;twenty&apos;, 30:&apos;thirty&apos;,40:&apos;forty&apos;,50:&apos;fifty&apos;,60:&apos;sixty&apos;,70:&apos;seventy&apos;, 80:&apos;eighty&apos;,90:&apos;ninety&apos;,100:&apos;hundred&apos;,1000:&apos;thousand&apos;&#125;def less_than_twenty(n): if n &lt;= 20 and n &gt;0: return mapping[n]def less_than_hundred(n): if n &gt; 20 and n &lt; 100: a,b = int(n/10),n%10 return mapping[a*10] if b == 0 else mapping[a*10]+mapping[b]def less_than_thousand(n): words=[] if n &gt;= 100 and n &lt;1000: a,b = int(n/100),n%100 words.append(mapping[a]) words.append(mapping[100]) if b&gt;0 and b&lt;=20: words.append(&apos;and&apos;) words.append(less_than_twenty(b)) if b&gt;20: words.append(&apos;and&apos;) words.append(less_than_hundred(b)) return &apos;&apos;.join(words)def get_words(n): if n&gt;0 and n&lt;=20: return less_than_twenty(n) elif n&lt;100: return less_than_hundred(n) elif n&gt;=100 and n&lt;1000: return less_than_thousand(n) elif n == 1000: return &apos;onethousand&apos;res = map(get_words,[x for x in range(1,1001)])print(sum(map(len,res))) 解析:此题中主要用到的点有 elif、join()、map函数以及用到了上一篇文章中 简介的 if/else 用法。 原理很简单，代码也很简单。先通过创建可哈希的字典对象，方便后面直接通过数字映射单词。然后通过判断区间，进行分别单词的获取。 map 函数是一个高级函数，接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回。 与之相似的还有 reduce 函数。把一个函数作用在一个序列上，函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算， 我之前在学 python 的时候，和 reduce 一起学的，有笔记，但是抄笔记是一件麻烦又无趣的事，如果后面又学到相关的高级应用，再贴代码吧。]]></content>
      <categories>
        <category>python</category>
        <category>exercise</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>菜鸟训练营</tag>
        <tag>sorted</tag>
        <tag>map</tag>
        <tag>reduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优秀代码一]]></title>
    <url>%2F2018%2F01%2F18%2F%E4%BC%98%E7%A7%80%E4%BB%A3%E7%A0%81%E7%89%87%E6%AE%B51%2F</url>
    <content type="text"><![CDATA[正所谓，人生苦短，我用 python 。在python 中，有非常多的令人影响深刻的好东西。 1.三目运算，if/else放在一行里面 12def test(m): return &apos;a&apos; if m==1 else &apos;b&apos; 2.构成一个字典序列 12print(dict(zip(&apos;abcd&apos;,range(4))) )&gt;&gt;&#123;&apos;a&apos;: 0, &apos;c&apos;: 2, &apos;b&apos;: 1, &apos;d&apos;: 3&#125; 3.print 中使用三目运算 1print(&apos;ok&apos; if a==1 else &apos;ko&apos;) 4.字符串切片的妙用 123 #列出1到20的数字，若是3的倍数就用apple代替，若是5的倍数就用orange代替， #若既是3的倍数又是5的倍数就用appleorange代替print [&apos;apple&apos;[i%35::]+&apos;orange&apos;[i%56::] or i for i in range(1,21)] 关键字or在上下文对算中，若有真假值，返回真值，若同为假值，返回最后一个假值 1234#&gt;&gt;&gt; print(&apos;&apos; or 1)1&gt;&gt;&gt; print(&apos;&apos;+&quot;&quot; or 1)1 5.推导列表生成字典 123list1=((1,&apos;a&apos;),(2,&apos;b&apos;))print(&#123;x[0]:x[1] for x in list1 &#125;)print(&#123;x:y for x in range(4) for y in range(10,14)&#125;) 6.漂亮的取表操作,字典排序 12345678910import heapqnums=[10,2,9,100,80]print heapq.nlargest(3,nums)print heapq.nsmallest(3,nums) students=[&#123;&apos;names&apos;:&apos;CC&apos;,&apos;score&apos;:100,&apos;height&apos;:189&#125;, &#123;&apos;names&apos;:&apos;BB&apos;,&apos;score&apos;:10,&apos;height&apos;:169&#125;, &#123;&apos;names&apos;:&apos;AA&apos;,&apos;score&apos;:80,&apos;height&apos;:179&#125;]print heapq.nsmallest(2,students,key=lambda x:x[&apos;height&apos;])]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>if/else</tag>
        <tag>code part</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F07%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post` bash$ hexo new “My New Post”` More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>Testing</tag>
        <tag>Another Tag</tag>
      </tags>
  </entry>
</search>
